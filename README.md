## Multimodal Alzheimer’s Detection: Speech & Text

### Introduction
Dementia is a category of neurodegenerative diseases that entails a long-term and usually gradual decrease in cognitive functioning. The main risk factor for dementia is age, and therefore its greatest incidence is among the elderly. Due to the severity of the situation worldwide, institutions and researchers are investing considerably in dementia prevention and early detection, focusing on disease progression. There is a need for cost-effective and scalable methods for the detection of dementia from its most subtle forms, such as the preclinical stage of Subjective Memory Loss (SML), to more severe conditions like Alzheimer's Dementia (AD) itself. 



### Objective  
Extending last semester’s separate audio- and text-based models on the **ADReSSo-2021** challenge corpus, we now merge both streams in a single multimodal pipeline. The system pairs **time-resolved paralinguistic speech features** (eGeMAPS) with **contextual language embeddings** generated from Whisper transcripts. By uniting *how* words are spoken with *what* they say, we test whether the fused representation yields a dementia classifier that is more robust and generalisable than either modality alone.

### Framework



### Methods


### Data Processing


### Results



### Conclusion


