## Multimodal Alzheimer’s Detection: Speech & Text

### Introduction
Dementia is a category of neurodegenerative diseases that entails a long-term and usually gradual decrease in cognitive functioning. The main risk factor for dementia is age, and therefore its greatest incidence is among the elderly. Due to the severity of the situation worldwide, institutions and researchers are investing considerably in dementia prevention and early detection, focusing on disease progression. There is a need for cost-effective and scalable methods for the detection of dementia from its most subtle forms, such as the preclinical stage of Subjective Memory Loss (SML), to more severe conditions like Alzheimer's Dementia (AD) itself. 



### Objective  
Extending last semester’s work on the **ADReSSo-2021** [1] dataset by moving from two separate models—one for audio, one for text—to a single **multimodal** approach. The new pipeline combines **time-based speech features** (eGeMAPS) with **text features** drawn from Whisper transcripts. By looking at *how* something is said and *what* is said at the same time, we test whether the fused view yields a dementia classifier that is sturdier and more generalisable than either source alone.

### Framework



### Methods


### Data Processing


### Results



### Conclusion




### References

[1] https://dementia.talkbank.org/ADReSSo-2021/
