## Multimodal Alzheimer’s Detection: Speech & Text

### Introduction
Dementia is a category of neurodegenerative diseases that entails a long-term and usually gradual decrease in cognitive functioning. The main risk factor for dementia is age, and therefore its greatest incidence is among the elderly. Due to the severity of the situation worldwide, institutions and researchers are investing considerably in dementia prevention and early detection, focusing on disease progression. There is a need for cost-effective and scalable methods for the detection of dementia from its most subtle forms, such as the preclinical stage of Subjective Memory Loss (SML), to more severe conditions like Alzheimer's Dementia (AD) itself. 



### Objective  
Using the **ADReSSo-2021** corpus [1], we extend last semester’s audio- and text-only models to a single **multimodal** approach. Recordings are encoded with frame-level eGeMAPS speech features and transformer-based sentence embeddings from Whisper transcripts. Fusing these vectors, we retrain our classifiers to test whether joining *how* words are spoken with *what* they say improves Alzheimer’s-dementia detection beyond either modality alone.

### Framework



### Methods


### Data Processing


### Results



### Conclusion




### References

[1] https://dementia.talkbank.org/ADReSSo-2021/
